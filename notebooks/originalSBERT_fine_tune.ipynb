{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " originalSBERT-fine-tune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClqewEEEh8Hd"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6_fHm2vmcyq"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w32QtfcQh_sg",
        "outputId": "0f08bed4-2976-4841-d567-ceb1e904021c"
      },
      "source": [
        "# Использовать gpu\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QZtTAhbiC0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47db0b2a-d7fb-4c31-b86a-a4478bd6224a"
      },
      "source": [
        "!pip install transformers\n",
        "!apt-get install unzip wget -y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "wget is already the newest version (1.19.4-1ubuntu2.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W98yFjQ3iJmd"
      },
      "source": [
        "PATH_TO_DISK = '/content/drive'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRjNOmM6iDZL",
        "outputId": "670c677c-b777-42ef-b6b5-76bf6856ad10"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(PATH_TO_DISK)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQFAlEAMkg3c"
      },
      "source": [
        "## Download pretrained model and pretrained tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97EEW0KGk-UC"
      },
      "source": [
        "PATH_TO_MODEL = 'sberbank-ai/sbert_large_nlu_ru'\n",
        "\n",
        "PATH_TO_PRETRAINED_TOKENIZER = 'sberbank-ai/sbert_large_nlu_ru'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zAdGmwbqBN-"
      },
      "source": [
        "# Загрузить sbertTokenizer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "sbertTokenizer = AutoTokenizer.from_pretrained(PATH_TO_PRETRAINED_TOKENIZER)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMmOvpibb9Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a77846-445c-4554-d4f0-3029a4441a67"
      },
      "source": [
        "# Загружаем модель.\n",
        "model = AutoModel.from_pretrained(PATH_TO_MODEL)\n",
        "\n",
        "# Переносим модель на GPU\n",
        "model.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 1024)\n",
              "    (token_type_embeddings): Embedding(2, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDz1sPxbcDXX",
        "outputId": "abb0db5c-c3fc-47c4-c767-ef80168247a0"
      },
      "source": [
        "# Проверим, что модель правильно загрузилась\n",
        "tokenized_sent = sbertTokenizer(['Инфляция - жуткая штука'], padding=True, truncation=True, max_length=20)\n",
        "inds = torch.tensor(tokenized_sent['input_ids'])\n",
        "attention_mask = torch.tensor(tokenized_sent['attention_mask'])\n",
        "inds_cuda = inds.to(device)\n",
        "attention_mask_cuda = attention_mask.to(device)\n",
        "model.eval()\n",
        "model(inds_cuda, attention_mask=attention_mask_cuda)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[-0.1171, -0.5547,  0.3396,  ...,  0.5373, -0.9762,  1.4210],\n",
              "                                                        [ 0.6806,  0.0290,  0.6023,  ...,  0.1934, -0.6857,  1.0496],\n",
              "                                                        [ 0.1594, -0.4141,  0.4344,  ..., -0.2450, -0.4732,  1.2877],\n",
              "                                                        [-0.0997, -0.5750,  0.5007,  ...,  0.3665, -0.1641,  1.0917],\n",
              "                                                        [-0.1514, -0.4705,  0.4593,  ...,  0.2352, -0.4895,  1.0387],\n",
              "                                                        [-0.3243, -0.2609, -0.6128,  ..., -0.1549, -0.9934,  0.6505]]],\n",
              "                                                      device='cuda:0', grad_fn=<NativeLayerNormBackward>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[ 0.8456,  0.2000, -0.9432,  ..., -0.0366, -0.9968,  0.1497]],\n",
              "                                                      device='cuda:0', grad_fn=<TanhBackward>))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L7o03DHWjzE"
      },
      "source": [
        "# Prepare data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Ur99khiRAC"
      },
      "source": [
        "# Путь к файлу с данными в .csv формате.\n",
        "# Здесь мы используем датасет Lenta.ru\n",
        "PATH_TO_DATA = os.path.join(PATH_TO_DISK, 'My Drive', 'Colab Notebooks/test-lenta.csv')\n",
        "\n",
        "# Если данные в .zip файле, предварительно их нужно распаковать и указать путь на распакованный .csv-файл\n",
        "# !unzip -o PATH_TO_DATA\n",
        "# PATH_TO_DATA = ...\n",
        "\n",
        "TOKENIZER_MAX_LENGHT = 20"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0nrDS8pm8IK"
      },
      "source": [
        "def getPreparedDataFromCSV(path, max_lenght):\n",
        "    '''\n",
        "    Принимает:  path - путь к .csv файлу с данными\n",
        "                max_lenght - параметр для токенизатора\n",
        "    Выдает:     input_ids - токенизированные предложения, torch.tensor\n",
        "                labels - класссы каждого предложения, которые мы должны научиться предсказывать, torch.tensor\n",
        "                id_to_topic - соответствие классов и реальных меток, list\n",
        "    '''\n",
        "    data = pd.read_csv(path)\n",
        "\n",
        "    topic_to_id = {}\n",
        "    id_to_topic = []\n",
        "    for topic in data.topic:\n",
        "        if not topic in topic_to_id:\n",
        "            topic_to_id[topic] = len(id_to_topic)\n",
        "            id_to_topic.append(topic)\n",
        "\n",
        "    labels = []\n",
        "    for topic in data.topic:\n",
        "        labels.append(topic_to_id[topic])\n",
        "    \n",
        "    input_ids = [] # encoded sentences\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in data.title:\n",
        "        encoded_input = sbertTokenizer(sent, padding='max_length',\n",
        "                                       truncation=True,\n",
        "                                       max_length=max_lenght,\n",
        "                                       return_tensors='pt')\n",
        "        input_ids.append(encoded_input['input_ids'])\n",
        "        attention_masks.append(encoded_input['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return input_ids, labels, attention_masks, id_to_topic"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5NyQViWANnj",
        "outputId": "9fbccf66-0fcb-4a27-b70c-a068ba13d78c"
      },
      "source": [
        "# Прочитаем данные из файла и рандомно разобьем их на датасеты\n",
        "# в отношении 7 : 2 : 1 для train : validation : test\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "input_ids, labels, attention_masks, id_to_topic = getPreparedDataFromCSV(PATH_TO_DATA, TOKENIZER_MAX_LENGHT)\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} testing samples'.format(test_size))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35,000 training samples\n",
            "10,000 validation samples\n",
            "5,000 testing samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkk3y_z_Fsep"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyc8ho17gdNv"
      },
      "source": [
        "trainingParameters = {\n",
        "    'optimizer' : {\n",
        "        'lr' : 2e-5,\n",
        "        'eps' : 1e-8\n",
        "    },\n",
        "    'epochs' : 2,\n",
        "    'batch_size' : 32\n",
        "}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oFeaUsBuXh3"
      },
      "source": [
        "# Создадим DataLoader для каждого датасета\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = trainingParameters['batch_size']\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "testing_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = SequentialSampler(test_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBILkBfKGLBe"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = trainingParameters['optimizer']['lr'],\n",
        "                  eps = trainingParameters['optimizer']['eps']\n",
        "                )\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tz1Pej3HwYZ"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = trainingParameters['epochs']\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r3Ja7qzIJLn"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwFf7BgJLnIA"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgqnctvOmgyC"
      },
      "source": [
        "# Инициализируем модель, которую будем тренировать\n",
        "# Здесь можно поиграть с количеством слоев и внутренних параметров\n",
        "# Я пробовала один линейный слой, два линейных слоя и число внутренних параметров (512, 512), (1024, 512), (512, 128)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = model\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.lin1 = nn.Linear(1024, 512)\n",
        "        self.lin2 = nn.Linear(512, len(id_to_topic))\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        if attention_mask == None:\n",
        "            attention_mask = torch.ones(x.shape[0])\n",
        "        x = self.model(x,\n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=attention_mask).pooler_output\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD3iBnkOq14k",
        "outputId": "81e9e581-c3e9-4ffd-9fe8-93864d5b84bb"
      },
      "source": [
        "net = Net()\n",
        "net.to(device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (lin2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syqaDKOELyKa",
        "outputId": "d9d04449-5986-4438-fa4b-629d727575ff"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# We'll store validation loss, validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print()\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_attention_mask = batch[1].cuda()\n",
        "        b_labels = batch[2].cuda()\n",
        "\n",
        "        net.zero_grad()\n",
        "        optimizer.zero_grad()  \n",
        "\n",
        "        result = net(b_input_ids, attention_mask=b_attention_mask)\n",
        "\n",
        "        loss = criterion(result, b_labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        del b_input_ids\n",
        "        del b_attention_mask\n",
        "        del b_labels\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "    \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_attention_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            result = net(b_input_ids, attention_mask=b_attention_mask)\n",
        "\n",
        "        loss = criterion(result, b_labels)\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        _, predicted = torch.max(result.data, 1)\n",
        "        total += b_labels.size(0)\n",
        "        correct += (predicted == b_labels).sum().item()\n",
        "\n",
        "        del b_input_ids\n",
        "        del b_attention_mask\n",
        "        del b_labels\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "\n",
        "\n",
        "    avg_val_accuracy = correct / total\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:44.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:01:28.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:02:12.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:02:56.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:03:40.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:04:24.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:05:09.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:05:53.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:06:37.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:07:21.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:08:05.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:08:49.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:09:33.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:10:17.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:11:02.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:11:46.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:12:30.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:13:14.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:13:58.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:14:42.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:15:26.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:16:09.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:16:53.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:17:37.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:18:21.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:19:05.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:19:49.\n",
            "\n",
            "  Average training loss: 1.06\n",
            "  Training epcoh took: 0:20:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.74\n",
            "  Validation took: 0:01:21\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:44.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:01:29.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:02:13.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:02:58.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:03:42.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:04:26.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:05:10.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:05:54.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:06:38.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:07:22.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:08:06.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:08:50.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:09:35.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:10:19.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:11:04.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:11:48.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:12:33.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:13:17.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:14:01.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:14:44.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:15:28.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:16:12.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:16:56.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:17:40.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:18:23.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:19:07.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:19:51.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:20:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.68\n",
            "  Validation took: 0:01:21\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:42:50 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2mr9A_Gb1qz"
      },
      "source": [
        "## Display statictics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8qFEazDNFXv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "9a83fcf2-d6bb-4606-acf7-1c53f4a23026"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df = df_stats.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.06</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:20:03</td>\n",
              "      <td>0:01:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:20:05</td>\n",
              "      <td>0:01:21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               1.06         0.74           0.79       0:20:03         0:01:21\n",
              "2               0.57         0.68           0.81       0:20:05         0:01:21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CutE55T6L4gr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9a8840a9-4b67-46f1-ae76-2592ca0bedb6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNZ1BkfrK7PZ"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDZlNbOKNeFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2227c9-5b63-4abb-e53d-af2d39e98029"
      },
      "source": [
        "net.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "print()\n",
        "print('Testing...')\n",
        "\n",
        "for (step, batch) in enumerate(testing_dataloader):\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "    \n",
        "    if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(testing_dataloader)))\n",
        "\n",
        "    b_input_ids, b_attention_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        result = net(b_input_ids, attention_mask=b_attention_mask)\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    _, predicted = torch.max(result.data, 1)\n",
        "\n",
        "    predictions.append(predicted)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "    del b_input_ids\n",
        "    del b_attention_mask\n",
        "    del b_labels\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing...\n",
            "  Batch    40  of    157.\n",
            "  Batch    80  of    157.\n",
            "  Batch   120  of    157.\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDb2mTW3Ufm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866868e6-3e57-4b65-e278-3ba872f584c6"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "predicted_labels = np.concatenate([np.array(prediction.to('cpu'), dtype='long') for prediction in predictions])\n",
        "\n",
        "y_true = np.concatenate(true_labels).flatten()\n",
        "y_pred = predicted_labels.flatten()\n",
        "\n",
        "print(\"Precision: {0:.4f}\".format(precision_score(y_true, y_pred, average='macro'))) # unweighted average of precisions\n",
        "print(\"Recall: {0:.4f}\".format(recall_score(y_true, y_pred, average='macro'))) # unweighted average of recalls\n",
        "print(\"F1-score: {0:.4f}\".format(f1_score(y_true, y_pred, average='macro'))) # unweighted average of f1-scores"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.8058\n",
            "Recall: 0.8061\n",
            "F1-score: 0.8057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugSLY13qWJ55"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltf0COQohwRW"
      },
      "source": [
        "OUTPUT_DIR = os.path.join(PATH_TO_DISK, 'My Drive')\n",
        "MODEL_NAME_TO_SAVE = 'sbert-original'\n",
        "PARAMETERS_NAME_TO_SAVE = 'args-sbert-original.bin'"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X4DxhvNRcfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d9400e-69c0-4eef-f257-e90e88e24da8"
      },
      "source": [
        "output_dir = './model_save'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save model, tokenizer and training arguments\n",
        "torch.save(net.state_dict(), os.path.join(output_dir, MODEL_NAME_TO_SAVE))\n",
        "sbertTokenizer.save_pretrained(output_dir)\n",
        "torch.save(trainingParameters, os.path.join(output_dir, PARAMETERS_NAME_TO_SAVE))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqNekoZXbvQU"
      },
      "source": [
        "Look at the sizes, out of curiousity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY8TekbTWsbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879cf8d4-f442-467a-ce53-e4870965dc7e"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1674300K\n",
            "-rw-r--r-- 1 root root       1K May 27 12:39 args-sbert-original.bin\n",
            "-rw-r--r-- 1 root root 1669851K May 27 12:39 sbert-original\n",
            "-rw-r--r-- 1 root root       1K May 27 12:39 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root       1K May 27 12:39 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    2689K May 27 12:39 tokenizer.json\n",
            "-rw-r--r-- 1 root root    1739K May 27 12:39 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiCvO-UgWgO9"
      },
      "source": [
        "Save to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YrXQIqpWfTG"
      },
      "source": [
        "torch.save(net.state_dict(), os.path.join(OUTPUT_DIR, MODEL_NAME_TO_SAVE))\n",
        "sbertTokenizer.save_pretrained(OUTPUT_DIR)\n",
        "torch.save(trainingParameters, os.path.join(OUTPUT_DIR, PARAMETERS_NAME_TO_SAVE))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-I1RKpGXGZT"
      },
      "source": [
        "To load model from drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiYeAnC5SbSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8de644-bb84-4b70-ea12-0348167ecc44"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Net class must be the same as class of the saved model. Initialize it somewehere before\n",
        "model = Net()\n",
        "\n",
        "model.load_state_dict(torch.load(os.path.join(output_dir, MODEL_NAME_TO_SAVE)))\n",
        "tokenizer = BertTokenizerFast.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (lin2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8c3T1gFcwSS"
      },
      "source": [
        "Done :)"
      ]
    }
  ]
}