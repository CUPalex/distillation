{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " originalSBERT-fine-tune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClqewEEEh8Hd"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6_fHm2vmcyq"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w32QtfcQh_sg",
        "outputId": "a2fdad8f-7220-4e14-8f43-15905ba1972b"
      },
      "source": [
        "# Использовать gpu\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QZtTAhbiC0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93d9688-fc3e-4e34-b72d-6d04c53888f5"
      },
      "source": [
        "!pip install transformers\n",
        "!apt-get install unzip wget -y"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "wget is already the newest version (1.19.4-1ubuntu2.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W98yFjQ3iJmd"
      },
      "source": [
        "PATH_TO_DISK = '/content/drive'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRjNOmM6iDZL",
        "outputId": "cb556fda-0ae7-462e-c9e2-a1cd16b87eb5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(PATH_TO_DISK)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQFAlEAMkg3c"
      },
      "source": [
        "## Download pretrained model and pretrained tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97EEW0KGk-UC"
      },
      "source": [
        "PATH_TO_MODEL = 'sberbank-ai/sbert_large_nlu_ru'\n",
        "\n",
        "PATH_TO_PRETRAINED_TOKENIZER = 'sberbank-ai/sbert_large_nlu_ru'"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zAdGmwbqBN-"
      },
      "source": [
        "# Загрузить sbertTokenizer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "sbertTokenizer = AutoTokenizer.from_pretrained(PATH_TO_PRETRAINED_TOKENIZER)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMmOvpibb9Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88c4800-c6cb-41ab-f66b-cd22380aaae3"
      },
      "source": [
        "# Загружаем модель.\n",
        "model = AutoModel.from_pretrained(PATH_TO_MODEL)\n",
        "\n",
        "# Переносим модель на GPU\n",
        "model.to(device)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 1024)\n",
              "    (token_type_embeddings): Embedding(2, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDz1sPxbcDXX",
        "outputId": "20560f20-831a-48d9-af42-955b0b4dfb97"
      },
      "source": [
        "# Проверим, что модель правильно загрузилась\n",
        "tokenized_sent = sbertTokenizer(['Инфляция - жуткая штука'], padding=True, truncation=True, max_length=20)\n",
        "inds = torch.tensor(tokenized_sent['input_ids'])\n",
        "attention_mask = torch.tensor(tokenized_sent['attention_mask'])\n",
        "inds_cuda = inds.to(device)\n",
        "attention_mask_cuda = attention_mask.to(device)\n",
        "model.eval()\n",
        "model(inds_cuda, attention_mask=attention_mask_cuda)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[-0.1171, -0.5547,  0.3396,  ...,  0.5373, -0.9762,  1.4210],\n",
              "                                                        [ 0.6806,  0.0290,  0.6023,  ...,  0.1934, -0.6857,  1.0496],\n",
              "                                                        [ 0.1594, -0.4141,  0.4344,  ..., -0.2450, -0.4732,  1.2877],\n",
              "                                                        [-0.0997, -0.5750,  0.5007,  ...,  0.3665, -0.1641,  1.0917],\n",
              "                                                        [-0.1514, -0.4705,  0.4593,  ...,  0.2352, -0.4895,  1.0387],\n",
              "                                                        [-0.3243, -0.2609, -0.6128,  ..., -0.1549, -0.9934,  0.6505]]],\n",
              "                                                      device='cuda:0', grad_fn=<NativeLayerNormBackward>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[ 0.8456,  0.2000, -0.9432,  ..., -0.0366, -0.9968,  0.1497]],\n",
              "                                                      device='cuda:0', grad_fn=<TanhBackward>))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L7o03DHWjzE"
      },
      "source": [
        "# Prepare data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Ur99khiRAC"
      },
      "source": [
        "# Путь к файлу с данными в .csv формате.\n",
        "# Здесь мы используем датасет Lenta.ru\n",
        "PATH_TO_DATA = os.path.join(PATH_TO_DISK, 'My Drive', 'Colab Notebooks/test-lenta.csv')\n",
        "\n",
        "# Если данные в .zip файле, предварительно их нужно распаковать и указать путь на распакованный .csv-файл\n",
        "# !unzip -o PATH_TO_DATA\n",
        "# PATH_TO_DATA = ...\n",
        "\n",
        "TOKENIZER_MAX_LENGHT = 20"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0nrDS8pm8IK"
      },
      "source": [
        "def getPreparedDataFromCSV(path, max_lenght):\n",
        "    '''\n",
        "    Принимает:  path - путь к .csv файлу с данными\n",
        "                max_lenght - параметр для токенизатора\n",
        "    Выдает:     input_ids - токенизированные предложения, torch.tensor\n",
        "                labels - класссы каждого предложения, которые мы должны научиться предсказывать, torch.tensor\n",
        "                id_to_topic - соответствие классов и реальных меток, list\n",
        "    '''\n",
        "    data = pd.read_csv(path)\n",
        "\n",
        "    topic_to_id = {}\n",
        "    id_to_topic = []\n",
        "    for topic in data.topic:\n",
        "        if not topic in topic_to_id:\n",
        "            topic_to_id[topic] = len(id_to_topic)\n",
        "            id_to_topic.append(topic)\n",
        "\n",
        "    labels = []\n",
        "    for topic in data.topic:\n",
        "        labels.append(topic_to_id[topic])\n",
        "    \n",
        "    input_ids = [] # encoded sentences\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in data.title:\n",
        "        encoded_input = sbertTokenizer(sent, padding='max_length',\n",
        "                                       truncation=True,\n",
        "                                       max_length=max_lenght,\n",
        "                                       return_tensors='pt')\n",
        "        input_ids.append(encoded_input['input_ids'])\n",
        "        attention_masks.append(encoded_input['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return input_ids, labels, attention_masks, id_to_topic"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5NyQViWANnj",
        "outputId": "68369540-d338-4149-e38d-e96db8c3823c"
      },
      "source": [
        "# Прочитаем данные из файла и рандомно разобьем их на датасеты\n",
        "# в отношении 7 : 2 : 1 для train : validation : test\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "input_ids, labels, attention_masks, id_to_topic = getPreparedDataFromCSV(PATH_TO_DATA, TOKENIZER_MAX_LENGHT)\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} testing samples'.format(test_size))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35,000 training samples\n",
            "10,000 validation samples\n",
            "5,000 testing samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkk3y_z_Fsep"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyc8ho17gdNv"
      },
      "source": [
        "trainingParameters = {\n",
        "    'optimizer' : {\n",
        "        'lr' : 2e-5,\n",
        "        'eps' : 1e-8\n",
        "    },\n",
        "    'epochs' : 4,\n",
        "    'batch_size' : 32\n",
        "}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oFeaUsBuXh3"
      },
      "source": [
        "# Создадим DataLoader для каждого датасета\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = trainingParameters['batch_size']\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "testing_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = SequentialSampler(test_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBILkBfKGLBe"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = trainingParameters['optimizer']['lr'],\n",
        "                  eps = trainingParameters['optimizer']['eps']\n",
        "                )\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tz1Pej3HwYZ"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = trainingParameters['epochs']\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r3Ja7qzIJLn"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwFf7BgJLnIA"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgqnctvOmgyC"
      },
      "source": [
        "# Инициализируем модель, которую будем тренировать\n",
        "# Здесь можно поиграть с количеством слоев и внутренних параметров\n",
        "# Я пробовала один линейный слой, два линейных слоя и число внутренних параметров (512, 512), (1024, 512), (512, 128)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = model\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.lin = nn.Linear(1024, len(id_to_topic))\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        if attention_mask == None:\n",
        "            attention_mask = torch.ones(x.shape[0])\n",
        "        x = self.model(x,\n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=attention_mask).pooler_output\n",
        "        x = self.dropout(x)\n",
        "        x = self.lin(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD3iBnkOq14k",
        "outputId": "7d4f62ea-8cd1-42b2-9482-ffda4135bd10"
      },
      "source": [
        "net = Net()\n",
        "net.to(device)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lin): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syqaDKOELyKa",
        "outputId": "2464cde7-ace2-4b4a-82cf-65d8743381b0"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# We'll store validation loss, validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print()\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_attention_mask = batch[1].cuda()\n",
        "        b_labels = batch[2].cuda()\n",
        "\n",
        "        net.zero_grad()\n",
        "        optimizer.zero_grad()  \n",
        "\n",
        "        result = net(b_input_ids, attention_mask=b_attention_mask)\n",
        "\n",
        "        loss = criterion(result, b_labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        del b_input_ids\n",
        "        del b_attention_mask\n",
        "        del b_labels\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "    \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_attention_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            result = net(b_input_ids, attention_mask=b_attention_mask)\n",
        "\n",
        "        loss = criterion(result, b_labels)\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        _, predicted = torch.max(result.data, 1)\n",
        "        total += b_labels.size(0)\n",
        "        correct += (predicted == b_labels).sum().item()\n",
        "\n",
        "        del b_input_ids\n",
        "        del b_attention_mask\n",
        "        del b_labels\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "\n",
        "\n",
        "    avg_val_accuracy = correct / total\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    40  of  1,094.    Elapsed: 0:00:24.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:48.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:01:12.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:01:36.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:02:00.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:02:24.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:02:48.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:03:12.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:03:36.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:04:00.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:04:24.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:04:48.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:05:12.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:05:36.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:06:00.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:06:24.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:06:48.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:07:12.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:07:35.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:07:59.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:08:23.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:08:47.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:09:11.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:09:35.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:09:59.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:10:23.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:10:47.\n",
            "\n",
            "  Average training loss: 1.76\n",
            "  Training epcoh took: 0:10:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 1.70\n",
            "  Validation took: 0:00:41\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:24.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:48.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:01:12.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:01:35.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:01:59.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:02:23.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:02:47.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:03:11.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:03:35.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:03:59.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:04:23.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:04:47.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:05:10.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:05:34.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:05:58.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:06:22.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:06:46.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:07:10.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:07:34.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:07:58.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:08:21.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:08:45.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:09:09.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:09:33.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:09:57.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:10:21.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:10:45.\n",
            "\n",
            "  Average training loss: 1.66\n",
            "  Training epcoh took: 0:10:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 1.67\n",
            "  Validation took: 0:00:41\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:24.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:48.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:01:11.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:01:35.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:01:59.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:02:23.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:02:47.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:03:10.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:03:34.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:03:58.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:04:22.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:04:46.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:05:10.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:05:33.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:05:57.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:06:21.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:06:45.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:07:09.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:07:32.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:07:56.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:08:20.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:08:44.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:09:08.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:09:32.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:09:55.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:10:19.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:10:43.\n",
            "\n",
            "  Average training loss: 1.63\n",
            "  Training epcoh took: 0:10:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 1.66\n",
            "  Validation took: 0:00:41\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,094.    Elapsed: 0:00:24.\n",
            "  Batch    80  of  1,094.    Elapsed: 0:00:48.\n",
            "  Batch   120  of  1,094.    Elapsed: 0:01:11.\n",
            "  Batch   160  of  1,094.    Elapsed: 0:01:35.\n",
            "  Batch   200  of  1,094.    Elapsed: 0:01:59.\n",
            "  Batch   240  of  1,094.    Elapsed: 0:02:23.\n",
            "  Batch   280  of  1,094.    Elapsed: 0:02:46.\n",
            "  Batch   320  of  1,094.    Elapsed: 0:03:10.\n",
            "  Batch   360  of  1,094.    Elapsed: 0:03:34.\n",
            "  Batch   400  of  1,094.    Elapsed: 0:03:58.\n",
            "  Batch   440  of  1,094.    Elapsed: 0:04:21.\n",
            "  Batch   480  of  1,094.    Elapsed: 0:04:45.\n",
            "  Batch   520  of  1,094.    Elapsed: 0:05:09.\n",
            "  Batch   560  of  1,094.    Elapsed: 0:05:33.\n",
            "  Batch   600  of  1,094.    Elapsed: 0:05:57.\n",
            "  Batch   640  of  1,094.    Elapsed: 0:06:20.\n",
            "  Batch   680  of  1,094.    Elapsed: 0:06:44.\n",
            "  Batch   720  of  1,094.    Elapsed: 0:07:08.\n",
            "  Batch   760  of  1,094.    Elapsed: 0:07:32.\n",
            "  Batch   800  of  1,094.    Elapsed: 0:07:55.\n",
            "  Batch   840  of  1,094.    Elapsed: 0:08:19.\n",
            "  Batch   880  of  1,094.    Elapsed: 0:08:43.\n",
            "  Batch   920  of  1,094.    Elapsed: 0:09:07.\n",
            "  Batch   960  of  1,094.    Elapsed: 0:09:30.\n",
            "  Batch 1,000  of  1,094.    Elapsed: 0:09:54.\n",
            "  Batch 1,040  of  1,094.    Elapsed: 0:10:18.\n",
            "  Batch 1,080  of  1,094.    Elapsed: 0:10:42.\n",
            "\n",
            "  Average training loss: 1.60\n",
            "  Training epcoh took: 0:10:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 1.66\n",
            "  Validation took: 0:00:41\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:46:11 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2mr9A_Gb1qz"
      },
      "source": [
        "## Display statictics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8qFEazDNFXv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8e217177-291f-44d7-92e1-a9d36c694e36"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df = df_stats.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.76</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:10:55</td>\n",
              "      <td>0:00:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.66</td>\n",
              "      <td>1.67</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:10:52</td>\n",
              "      <td>0:00:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.63</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:10:51</td>\n",
              "      <td>0:00:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.60</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:10:49</td>\n",
              "      <td>0:00:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               1.76         1.70           0.76       0:10:55         0:00:41\n",
              "2               1.66         1.67           0.78       0:10:52         0:00:41\n",
              "3               1.63         1.66           0.79       0:10:51         0:00:41\n",
              "4               1.60         1.66           0.80       0:10:49         0:00:41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CutE55T6L4gr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "fd100133-6b28-4688-994b-a8163fc267a8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNZ1BkfrK7PZ"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDZlNbOKNeFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcbf568-7a6d-499f-d26e-29755d3dd76d"
      },
      "source": [
        "net.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "print()\n",
        "print('Testing...')\n",
        "\n",
        "for (step, batch) in enumerate(testing_dataloader):\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    if len(batch[0]) != batch_size:\n",
        "            continue\n",
        "    \n",
        "    if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(testing_dataloader)))\n",
        "\n",
        "    b_input_ids, b_attention_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        result = net(b_input_ids, attention_mask=b_attention_mask)\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    _, predicted = torch.max(result.data, 1)\n",
        "\n",
        "    predictions.append(predicted)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "    del b_input_ids\n",
        "    del b_attention_mask\n",
        "    del b_labels\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    40  of    157.\n",
            "  Batch    80  of    157.\n",
            "  Batch   120  of    157.\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDb2mTW3Ufm3"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "predicted_labels = np.concatenate([np.array(prediction.to('cpu'), dtype='long') for prediction in predictions])\n",
        "\n",
        "y_true = np.concatenate(true_labels).flatten()\n",
        "y_pred = predicted_labels.flatten()\n",
        "\n",
        "print(\"Precision: {0:.4f}\".format(precision_score(y_true, y_pred, average='macro'))) # unweighted average of precisions\n",
        "print(\"Recall: {0:.4f}\".format(recall_score(y_true, y_pred, average='macro'))) # unweighted average of recalls\n",
        "print(\"F1-score: {0:.4f}\".format(f1_score(y_true, y_pred, average='macro'))) # unweighted average of f1-scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugSLY13qWJ55"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltf0COQohwRW"
      },
      "source": [
        "OUTPUT_DIR = os.path.join(PATH_TO_DISK, 'My Drive')\n",
        "MODEL_NAME_TO_SAVE = 'sbert-original'\n",
        "PARAMETERS_NAME_TO_SAVE = 'args-sbert-original.bin'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X4DxhvNRcfb"
      },
      "source": [
        "output_dir = './model_save'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save model, tokenizer and training arguments\n",
        "torch.save(net.state_dict(), os.path.join(output_dir, MODEL_NAME_TO_SAVE))\n",
        "sbertTokenizer.save_pretrained(output_dir)\n",
        "torch.save(trainingParameters, os.path.join(output_dir, PARAMETERS_NAME_TO_SAVE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqNekoZXbvQU"
      },
      "source": [
        "Look at the sizes, out of curiousity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY8TekbTWsbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae15747a-de2f-45c9-8572-1d69750c3b4f"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1672268K\n",
            "-rw-r--r-- 1 root root       1K May 29 12:17 args-sbert-original.bin\n",
            "-rw-r--r-- 1 root root 1667820K May 29 12:17 sbert-original\n",
            "-rw-r--r-- 1 root root       1K May 29 12:17 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root       1K May 29 12:17 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    2689K May 29 12:17 tokenizer.json\n",
            "-rw-r--r-- 1 root root    1739K May 29 12:17 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiCvO-UgWgO9"
      },
      "source": [
        "Save to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YrXQIqpWfTG"
      },
      "source": [
        "torch.save(net.state_dict(), os.path.join(OUTPUT_DIR, MODEL_NAME_TO_SAVE))\n",
        "sbertTokenizer.save_pretrained(OUTPUT_DIR)\n",
        "torch.save(trainingParameters, os.path.join(OUTPUT_DIR, PARAMETERS_NAME_TO_SAVE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-I1RKpGXGZT"
      },
      "source": [
        "To load model from drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiYeAnC5SbSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0efe31-b744-4e8e-e397-1cbb7543a443"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Net class must be the same as class of the saved model. Initialize it somewehere before\n",
        "model = Net()\n",
        "\n",
        "model.load_state_dict(torch.load(os.path.join(output_dir, MODEL_NAME_TO_SAVE)))\n",
        "tokenizer = BertTokenizerFast.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lin): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8c3T1gFcwSS"
      },
      "source": [
        "Done :)"
      ]
    }
  ]
}